# Path: /bedrock_chatbot_app/ui/chat_interface.py

"""
ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ê´€ë ¨ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ Streamlit ê¸°ë°˜ì˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬, ì‘ë‹µ ìƒì„±, ì±„íŒ… ê¸°ë¡ í‘œì‹œ ë° íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì‹œê°í™” ê¸°ëŠ¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""
import streamlit as st
import time
import json
from lib.invoke_model import invoke_model
from lib.converse import converse
from lib.knowledge_base import query_knowledge_base
from lib.agent import invoke_agent
from lib.flow import invoke_flow
from lib.trace_utils import ensure_json_serializable
from lib.logging_config import logger


def init_chat():
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” - í•„ìš”í•œ ì„¸ì…˜ ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
    # ê¸°ë³¸ ì±„íŒ… ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    if "current_trace" not in st.session_state:
        st.session_state.current_trace = None
    if "converse_history" not in st.session_state:
        st.session_state.converse_history = []
    
    # ì²˜ë¦¬ ìƒíƒœ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
    if "processing_status" not in st.session_state:
        st.session_state.processing_status = {
            "is_processing": False,
            "current_prompt": None,
            "current_mode": None
        }
    if "pending_message" not in st.session_state:
        st.session_state.pending_message = None
        
    # ê¸°ë³¸ ì‘ë‹µ ëª¨ë“œ ì„¤ì •
    if "response_mode" not in st.session_state:
        st.session_state.response_mode = "Foundation Model"


def add_message(role, content, response_type=None):
    """ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤"""
    message = {
        "role": role,
        "content": content,
        "timestamp": time.time()
    }
    
    if role == "assistant" and response_type:
        message["response_type"] = response_type
    
    st.session_state.chat_messages.append(message)


def display_chat_history():
    """ì €ì¥ëœ ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤"""
    # ì €ì¥ëœ ë©”ì‹œì§€ í‘œì‹œ
    for msg_idx, msg in enumerate(st.session_state.chat_messages):
        with st.chat_message(msg["role"]):
            # ì‘ë‹µ ìœ í˜• í‘œì‹œ (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
            if msg["role"] == "assistant" and "response_type" in msg:
                response_type_display = get_response_type_display(msg["response_type"])
                st.caption(f"ì‘ë‹µ ìœ í˜•: {response_type_display}")
            
            # ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
            st.markdown(msg["content"])
            
            # íŠ¸ë ˆì´ìŠ¤ ì •ë³´ í‘œì‹œ (Agent/Flowì¸ ê²½ìš°)
            if msg["role"] == "assistant" and msg.get("response_type") in ["agent", "flow"]:
                display_trace_info(msg_idx)
    
    # ëŒ€ê¸° ì¤‘ì¸ ë©”ì‹œì§€ í‘œì‹œ
    if st.session_state.pending_message:
        with st.chat_message("assistant"):
            st.write("ìƒê° ì¤‘...")


def display_trace_info(msg_idx):
    """íŠ¹ì • ë©”ì‹œì§€ì™€ ì—°ê´€ëœ íŠ¸ë ˆì´ìŠ¤ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤"""
    trace_available = 'current_trace' in st.session_state and st.session_state.current_trace is not None
    
    if trace_available:
        trace_data = st.session_state.current_trace.get("trace_data", {})
        
        with st.expander("ğŸ” íŠ¸ë ˆì´ìŠ¤ ì •ë³´", expanded=False):
            if "orchestrationTrace" in trace_data:
                display_orchestration_trace(trace_data["orchestrationTrace"], msg_idx)
            else:
                st.json(trace_data)
    else:
        with st.expander("âš ï¸ íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì—†ìŒ", expanded=False):
            st.warning("íŠ¸ë ˆì´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def display_orchestration_trace(trace, msg_idx):
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ìŠ¤í…ë³„ë¡œ í‘œì‹œí•©ë‹ˆë‹¤"""
    # ìŠ¤í… ì •ë³´ ì¶”ì¶œ
    steps = trace.get("invocationInput", {}).get("steps", [])
    
    if not steps:
        st.warning("ìŠ¤í… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.json(trace)
        return
    
    # ìš”ì•½ íƒ­ê³¼ ìŠ¤í…ë³„ íƒ­ ìƒì„±
    tab_titles = ["ìš”ì•½"] + [f"ìŠ¤í… {i+1}" for i in range(len(steps))]
    tabs = st.tabs(tab_titles)
    
    # ìš”ì•½ íƒ­
    with tabs[0]:
        st.subheader("ì‹¤í–‰ ìš”ì•½")
        st.write(f"ì´ ìŠ¤í… ìˆ˜: {len(steps)}ê°œ")
        
        for i, step in enumerate(steps):
            step_type = "API í˜¸ì¶œ" if "action" in step else "ë‚´ë¶€ ì²˜ë¦¬"
            if "action" in step:
                api_path = step.get("action", {}).get("apiPath", "Unknown API")
                st.markdown(f"**ìŠ¤í… {i+1}**: {step_type} - {api_path}")
            else:
                st.write(f"**ìŠ¤í… {i+1}**: {step_type}")
    
    # ê° ìŠ¤í… íƒ­
    for i, step in enumerate(steps):
        with tabs[i+1]:
            st.subheader(f"ìŠ¤í… {i+1} ìƒì„¸ ì •ë³´")
            step_type = "API í˜¸ì¶œ" if "action" in step else "ë‚´ë¶€ ì²˜ë¦¬"
            st.write(f"**ìœ í˜•**: {step_type}")
            
            if "action" in step:
                action = step["action"]
                st.write(f"**API ê²½ë¡œ**: {action.get('apiPath', 'Unknown')}")
                st.write(f"**ë©”ì„œë“œ**: {action.get('httpMethod', 'Unknown')}")
                
                parameters = action.get("parameters", [])
                if parameters:
                    st.write("**íŒŒë¼ë¯¸í„°:**")
                    for param in parameters:
                        st.write(f"- {param.get('name')}: {param.get('value')}")
            
            with st.expander("ì „ì²´ ìŠ¤í… ë°ì´í„°", expanded=False):
                st.json(step)


def show_flow_trace(trace_data, msg_idx):
    """Flow íŠ¸ë ˆì´ìŠ¤ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤"""
    if "flow_execution_id" in trace_data:
        st.write(f"**Flow ì‹¤í–‰ ID**: {trace_data['flow_execution_id']}")
    
    if 'flow_extracted_data' in st.session_state:
        st.subheader("ì…ë ¥ìœ¼ë¡œ ì¶”ì¶œëœ ë°ì´í„°")
        st.json(st.session_state.flow_extracted_data)
    
    with st.expander("ì „ì²´ Flow íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°", expanded=False):
        st.json(trace_data)


def get_response_type_display(response_type):
    """ì‘ë‹µ ìœ í˜•ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤"""
    type_map = {
        "foundation_model": "íŒŒìš´ë°ì´ì…˜ ëª¨ë¸",
        "converse": "Converse API",
        "retrieve": "Knowledge Base (Retrieve API)",
        "retrieve_and_generate": "Knowledge Base (RetrieveandGenerate API)",
        "agent": "Agent",
        "flow": "Flow",
        "error": "ì˜¤ë¥˜"
    }
    
    return type_map.get(response_type, response_type)


def handle_sample_prompt(prompt):
    """ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
    if st.session_state.processing_status["is_processing"]:
        return False
        
    current_mode = st.session_state.response_mode
    
    st.session_state.processing_status = {
        "is_processing": True,
        "current_prompt": prompt,
        "current_mode": current_mode
    }
    
    add_message("user", prompt)
    st.session_state.pending_message = True
    st.rerun()


def process_user_input(user_input):
    """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
    if not user_input:
        return False
        
    # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
    if st.session_state.processing_status["is_processing"]:
        return False
    if user_input == st.session_state.processing_status.get("current_prompt"):
        return False
    
    response_mode = st.session_state.response_mode
    
    # ë¡œê¹…
    logger.info(f"ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì‹œì‘: '{user_input}'")
    logger.info(f"í˜„ì¬ ì‘ë‹µ ëª¨ë“œ: {response_mode}")
    
    if response_mode == "Agent":
        logger.info(f"Agent API í˜¸ì¶œ - enableTrace: {st.session_state.get('agent_enable_trace', True)}")
    elif response_mode == "Flow":
        logger.info(f"Flow API í˜¸ì¶œ - enableTrace: {st.session_state.get('flow_enable_trace', True)}")
    
    # ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
    st.session_state.processing_status = {
        "is_processing": True,
        "current_prompt": user_input,
        "current_mode": response_mode
    }
    
    add_message("user", user_input)
    st.session_state.pending_message = True
    st.rerun()


def check_pending_response():
    """ëŒ€ê¸° ì¤‘ì¸ ì‘ë‹µì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤"""
    if (st.session_state.processing_status["is_processing"] and 
        st.session_state.pending_message):
        
        prompt = st.session_state.processing_status["current_prompt"]
        mode = st.session_state.processing_status["current_mode"]
        
        try:
            # ì‘ë‹µ ìƒì„±
            response_data = generate_response(prompt, mode)
            output = response_data.get("output", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            response_type = response_data.get("response_type", "unknown")
            
            # ë””ë²„ê·¸ ì •ë³´ ì²˜ë¦¬
            if "debug_info" in response_data:
                logger.info(f"ì‘ë‹µ ë””ë²„ê·¸ ì •ë³´: {response_data['debug_info']}")
            
            # íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì²˜ë¦¬
            if "trace" in response_data and response_data["trace"]:
                process_trace_data(response_data, response_type)
            else:
                logger.warning("íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì—†ìŒ")
                st.session_state.current_trace = None
            
            # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
            add_message("assistant", output, response_type)
            
            # Converse API ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
            if response_data.get("response_type") == "converse" and "conversation_history" in response_data:
                st.session_state.converse_history = response_data["conversation_history"]
        
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            add_message("assistant", f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
        
        finally:
            # ì²˜ë¦¬ ì™„ë£Œ
            st.session_state.processing_status["is_processing"] = False
            st.session_state.pending_message = None


def process_trace_data(response_data, response_type):
    """íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤"""
    trace_data = response_data["trace"]
    trace_type = type(trace_data).__name__
    trace_keys = list(trace_data.keys()) if isinstance(trace_data, dict) else "N/A"
    
    logger.info(f"íŠ¸ë ˆì´ìŠ¤ ì •ë³´: ì¡´ì¬=True, íƒ€ì…={trace_type}, í‚¤={trace_keys}")
    
    # íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì €ì¥
    st.session_state.current_trace = {
        "trace_data": ensure_json_serializable(trace_data),
        "response_type": response_type,
        "timestamp": time.time()
    }
    logger.info("âœ… íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì €ì¥ ì™„ë£Œ")
    
    # ë””ë²„ê¹…ìš© íŒŒì¼ ì €ì¥
    try:
        with open("last_trace.json", "w") as f:
            json.dump(ensure_json_serializable(trace_data), f, indent=2)
    except Exception as e:
        logger.warning(f"íŠ¸ë ˆì´ìŠ¤ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


def generate_response(prompt, mode):
    """ì„ íƒëœ ëª¨ë“œì— ë”°ë¼ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤"""
    
    # Foundation Model ëª¨ë“œ
    if mode == "Foundation Model":
        model_id = st.session_state.get("model_id")
        # ì´ ë¶€ë¶„ì„ ìˆ˜ì •:
        response = invoke_model(prompt, model_id)  # invoke_foundation_model -> invoke_model
        return {
            "response_type": "foundation_model",
            "output": response
        }
    
    # Converse API ëª¨ë“œ
    elif mode == "Converse API":
        model_id = st.session_state.get("model_id")
        temperature = st.session_state.get("temperature", 0.7)
        max_tokens = st.session_state.get("max_tokens", 1024)
        
        return invoke_converse(
            prompt, 
            conversation_history=st.session_state.converse_history,
            model_id=model_id,
            temperature=temperature,
            max_tokens=max_tokens
        )
    
    # Knowledge Base Retrieve ëª¨ë“œ
    elif mode == "Knowledge Base (Retrieve)":
        kb_id = st.session_state.get("knowledge_base_id")
        response = query_knowledge_base(prompt, kb_id, retrieve_only=True)
        
        # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
        if response.get("results"):
            response["output"] = format_kb_results(response["results"])
        else:
            response["output"] = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
        return response
    
    # Knowledge Base Retrieve & Generate ëª¨ë“œ
    elif mode == "Knowledge Base (Retrieve & Generate)":
        kb_id = st.session_state.get("knowledge_base_id")
        return query_knowledge_base(prompt, kb_id, retrieve_only=False)
    
    # Agent ëª¨ë“œ
    elif mode == "Agent":
        agent_id = st.session_state.get("agent_id")
        agent_alias_id = st.session_state.get("agent_alias_id")
        enable_trace = True
        
        logger.info(f"Agent API í˜¸ì¶œ - enableTrace: {enable_trace}")
        
        return invoke_agent(prompt, agent_id=agent_id, 
                           agent_alias_id=agent_alias_id,
                           enable_trace=enable_trace)
    
    # Flow ëª¨ë“œ
    elif mode == "Flow":
        flow_id = st.session_state.get("flow_id")
        flow_alias_id = st.session_state.get("flow_alias_id")
        enable_trace = True
        
        logger.info(f"Flow API í˜¸ì¶œ - enableTrace: {enable_trace}")
        
        response = invoke_flow(
            prompt, 
            flow_id=flow_id,
            flow_alias_id=flow_alias_id,
            enable_trace=enable_trace
        )
        
        # ì¶”ì¶œëœ ë°ì´í„° ì €ì¥
        if "extracted_data" in response:
            st.session_state.flow_extracted_data = response["extracted_data"]
            
        return response
    
    # ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ
    else:
        return {
            "response_type": "error",
            "output": f"ì„ íƒí•œ ì‘ë‹µ ëª¨ë“œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {mode}"
        }


def format_kb_results(results):
    """ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤"""
    formatted_output = f"## ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)\n\n"
    
    for i, result in enumerate(results):
        formatted_output += f"### ê²°ê³¼ {i+1} (ì ìˆ˜: {result['score']:.4f})\n"
        formatted_output += f"{result['content']}\n\n"
        
        source = result.get('source', 'Unknown')
        filename = result.get('source_filename', 'Unknown')
        formatted_output += f"**ì¶œì²˜:** [{filename}]({source})\n\n---\n\n"
    
    return formatted_output